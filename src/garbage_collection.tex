\newpage
\section{Циклический сборщик мусора}
\label{section:dangling}

Рассмотрим поисковую систему, хранилище которой основано на LSM-дереве,
использующем битмап индексы в качестве значений. Назовем \textit{первичным}
LSM-индексом индекс, состоящий из битмап документов с определенными признаками,
а \textit{вторичным} — индекс, используемый для фактического поиска документов
по \textit{docID}. Таким образом, изначальный поиск документов осуществляется в
\textit{первичном} индексе, а найденные документы проверяются на актуальность
во \textit{вторичном}.

Документ при добавлении анализируется и делится на значимые признаки вида
\textit{дата}, \textit{текст}, \textit{маркер} и другие. Каждый признак
принимает множество уникальных значений, а каждое значение однозначно определяется
\textit{ID} признака и значения. Каждому документу присваивается уникальный
\textit{docID}, соответствующий единственному объекту.

Как было указано ранее (см. с.~\pageref{table}), данные можно представить в виде
таблицы, где строка отвечает за определенный признак и его значение, а столбец
— за документ. Из-за огромного количества документов и меньшего количества
уникальных значений признаков битмапы обычно сильно разрежены, поэтому длинная
строка битмапы поделена на блоки равного размера $(\sim 2^{x})$ и хранится в
сжатом виде.

\begin{table}[H]
\caption{Логическое представление индекса}
\centering
\small
\singlespacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \hline
                &\multicolumn{3}{c|}{block1}&\multicolumn{3}{c|}{block2}& \ldots \\ \hline
                & doc1  & doc2  & doc3      & doc4  & doc5      & doc6  & \ldots \\ \hline
    feature 1   & 0     & 0     & 0         & 1     & 1         & 1     & \ldots \\ \hline
    feature 2   & 1     & 0     & 1         & 0     & 1         & 1     & \ldots \\ \hline
    \vdots      & \vdots& \vdots& \vdots    & \vdots& \vdots    &\vdots & $\ddots$ \\ \hline
\end{tabular}
\label{index}
\end{table}

Поиск производится путем поиска в LSM-дереве, где ключом выступает
\{\textit{feature id + field id + blockid}\}, а значением — блок битмапы.
Конкретный бит однозначно отвечает за ID документа \textit{docId = ID блока
$\cdot$ число бит в блоке + бит}.

\subsection{Добавление новых блоков взамен мусорных}

Определим пороговое целое значение \textit{dangling} для индекса в первичном
LSM-дереве. Оно равно допустимому количеству \textit{повисших} документов в
блоке. Также добавим в индекс структуру данных, карту \textit{danglingBmap}, для
отображения блоков в индексе в битмапы, содержащие биты \textit{повисших}
документов в блоке. В случае, если число \textit{повисших} документов в блоке
превышает пороговое — будем считать блок \textit{мусорным}.

При получении запроса на удаление документа:
\begin{itemize}
    \item выполним его логическое удаление из вторичного LSM-индекса.
    \item проставим бит удаленного документа в битмапе, полученную из
    \textit{danglingBmap} по ключу — блоку, содержащему \textit{повисший} документ.
\end{itemize}

\textit{Замечание}: операция записи в danglingBmap должна быть атомарной для 
избежания состояний гонок и критических секций во время сбора мусора. В нашей
работе используется примитив синхронизации мьютекс.

На этом процедура удаления документа заканчивается до вызова сбора мусора в индексе.
В нашей прототипе сбор мусора запускается через равные промежутки времени, определяемые 
гиперпараметром системы. Также возможен динамический расчет промежутка времени,
через который требуется запуск алгоритма, в зависимости от количества запросов на
добавление, удаление и запись.

\textbf{Алгоритм сбора мусора}:
\begin{enumerate}
    \item Для каждого блока в карте \textit{danglingBmap} проверить, превышает
    ли мощность битмапы (число ненулевых битов) допустимое пороговое значение
    для индекса.
    \item В случае отсутствия таких элементов закончить сбор мусора, так
    как он будет неэффективен.
    \item В противном случае: \begin{enumerate}
        \item Для каждого блока, в котором мощность \textit{повисшей} битмапы
        превысила пороговое значение, выполнить операцию \textit{НЕ И} с битмапой,
        полученной из \textit{первичного} индекса. Полученная битмапа не содержит
        удаленных документов. Оставшиеся документы проверить во \textit{вторичном}
        индексе на актуальность ключа (документа).
        \item Присвоить живым документам новый \textit{docId} и обновить
        на них ссылку во \textit{вторичном} индексе.
        \item Продублировать значения битов в битмапах для новых \textit{docId}
        в \textit{первичном} индексе.
        \item Удалить блок данных для старых \textit{docId}.
        \item В конце сбора мусора обнулить  \textit{danglingBmap} для старого
        \textit{docId}.
    \end{enumerate}
\end{enumerate}

Подсчитаем объем памяти, необходимый для хранения дополнительной карты
\textit{danglingBmap}. Согласно \cite{Roaring:2019} несжатое битовое множество
на $10^6$ документов занимается порядка 100kB памяти. Тогда для 20MB текста
(документов) и размера блока в $10^6$ элементов потребуется в худшем случае
(все блоки не сжаты) 2MB дополнительной памяти для карты удаленных документов.
Этот объем памяти можно хранить в быстрой памяти, иногда выполняя сериализацию
в долгосрочную память. В случае же $10^9$ документов потребуется дополнительная
структура для удобного поиска и хранение во внешней памяти.

\subsection{Переиспользование \textit{docId}}

Альтернативный метод — использовать старые \textit{docId} \textit{повисших}
документов вместо создания новых блоков.

Раннее предполагалось, что документы не могут быть обновлены в поисковом
индексе, а параметр \textit{lastDocId} никогда не уменьшается.

Определим структуру данных, в которых будем хранить \textit{docId} повисших
документов. От структуры мы потребуем быстрый поиск, добавление и удаление
элементов: например, B-дерево (АВЛ, 2-3, $B^{+}$, vEB).
Назовем дерево \textit{danglingTree}.

Процедура удаления документа:
\begin{enumerate}
    \item Обнулим значения битов для каждого признака удаленного документа.
    \item Добавим \textit{docId} документа в \textit{dangling} дерево.
\end{enumerate}

Процедура добавления документа:
\begin{enumerate}
    \item Проверим, не пусто ли \textit{dangling} дерево.
    \item В случае существования \textit{повисшей} ссылки:
    \begin{enumerate}
        \item Удаляем минимальное или произвольное значение \textit{docId} из
        \textit{danglingTree}, предварительно сохранив его.
        \item Записанное значение \textit{docId} присваиваем новому документу.
    \end{enumerate}
    \item В противном случае присваиваем новому документу \textit{docId} равный
    \textit{lastDocId + 1} и инкрементируем значение \textit{lastDocId}.
\end{enumerate}

Гибридные подходы, как, например, \textit{roaring bitmaps} используют одновременно
три разных представления для битмапов и балансируют между ними, чтобы
максимизировать производительность и минимизировать потребление памяти \cite{Roaring:2019}.
Однако при таком подходе в индексе окажется много плотных битмап, и операции над
ними занимают линейное от длины битмапы вместе с нулями время, причём значительная
часть полученных битов потом фильтруется, что требует дополнительных структур
данных или просмотров LSM-индекса.

\subsection{Мгновенное удаление}

Для анализа эффективности алгоритма логично сравнить его с архитектурой без мусора:
при каждом запросе на удаление счищаем все ненулевые биты в битмапах для конкретного
документа.

Данное решение аналогично удалению столбца в разреженной матрице. На это потребуется
множество дополнительных обращений в память, ведь каждый блок строки — это
отдельно лежащая в памяти битмапа для конкретного признака и его значения.

Очевидно, что каждый раз проходить по всем признака индекса слишком затратно. Создадим
дополнительную структуру данных, карту \textit{doc2FieldFeature}, для отображения
документов в набор их признаков и значений.

\textit{Замечание}: данная структуру должна заполняться уже после анализа документа на
признаки и последующей обработки их строкового/числового/календарного
представлений в \textit{ID}. Это обусловлено следующими причинами:
\begin{itemize}
    \item Синтаксический анализатор текста может несколько меняться со временем,
    чтобы он оставался корректным с точки зрения пользователя. Однако,
    полученное таким образом при добавлении документа множество \textit{ID} признаков,
    которые были добавлены в \textit{первичный} индекс, не будет точно совпадать с
    результирующим множеством \textit{ID} признаков при смене анализатора.
    \item На каждую операцию удаления потребуется дополнительная операция перевода
    первоначального представления признаков в их \textit{ID}, что потребует лишнего
    времени.
    \item Хранение признаков в виде, полученном из документа, потребует больше
    памяти, чем их представление в виде \textit{ID}.
\end{itemize}

Таким образом, при добавлении документа запишем в описанную выше структуру набор
\textit{ID} признаков и значений, которые вставим в \textit{первичный} индекс.

Рассмотрим структуру элемента \textit{первичного} индекса в общем случае. Элемент
\textit{entry} состоит из идентификатора признака, его значения, блока битмапы,
содержащей множество документов и специального маркера удаления
\textit{tombstone}. Для реализации качественного мгновенного удаления добавим в
структуру \textit{entry} битмапу удаленных документов.

При получении запроса на удаление документа для каждого его признака и
значения из отображения \textit{doc2FieldFeature} выполним вставку в
\textit{первичный} индекс элемента с указанными признаком, значением, блоком,
вычисленным для нужного документа и битмапой, состоящей из 1 бита — позиции
документа в блоке. Данный элемент сольется с элементом с такими же признаком,
значением и блоком в индексе.

При вставке в индекс в случае сбора мусора мы выполняли операцию побитового
\textit{ИЛИ} для двух битмап, тем самым, сливая документы с добавленными ранее.
Сейчас же требуется иной алгоритм. При слиянии нового и старого элементов
индекса:
\begin{enumerate}
    \item Битмапа удаленных документов для результирующего элемента индекса
    получится результатом побитовой операции \textit{ИЛИ} битмап удаленных
    документов для старого и нового элементов. Таким образом, мы учитываем
    документы, удаленные за всю историю существования документа.
    \item Главная битмапа результирующего элемента образуется после применения
    операции побитового \textit{ИЛИ} нового и старого элементов индекса. Далее к 
    полученной битмапе применяется операция побитового \textit{НЕ И} с полученной
    выше битмапой удаленных документов. Таким образом, все добавленные когда-либо
    документы будут очищены от когда-либо удаленных документов. 
\end{enumerate}

Удаление может называться мгновенным, так как вставка бита в индекс и операция
слияния происходит сразу же при удалении вместо вставки лишь маркера удаления и
удаления лишь при записи на диск и долго слияния в множеством структур.

\subsection{Теоретическое сравнение затраченных ресурсов}
\label{theory}
\subsubsection{Алгоритм сбора мусора}

Допустим, мы добавили $N$ документов в индекс, удалили $D$ документов.
До момента сбора мусора в индексе останется
\begin{equation}
    \label{alpha}
    \vec{F} \cdot \vec{D} = \alpha
\end{equation}
мусорных бит, где $\vec{D}$ — единичный вектор размерности $D$, 
а $\vec{F}$ — вектор, состоящий из числа признаков для $i$-ого удаленного документа.

Мы заполнили значения в $b$ блоках \textit{danglingBmap}, что добавило $b$ блоков в карту.
Получается 
\begin{equation}
    \label{eta}
    b \cdot (\tau + \beta) ~= D \cdot \beta' = \eta
\end{equation}
бит, где $\beta$ — коэффициент хранения структуры карты из алгоритмов устройства
карт в Golang, $\tau$ — размер блока, $\beta'$ —  средний коэффициент
распределения битов в блоках битмап, от которого зависит способ их кодирования.

Каждый из $\gamma (\leq b)$ <<мусорных>> блоков для единого признака будет удален с перераспределением живых
элементов в новые блоки. Общее число живых элементов в мусорном блоке 
\begin{equation}
    \gamma \cdot \tau - D_{\gamma} = \rho,
\end{equation}
где $D_{\gamma}$ — число удаленных документов в $\gamma$ блоках, и алгоритм создаст
\begin{equation}
    \left\lceil \frac{\rho}{\tau}\right\rceil = \vartheta 
\end{equation}
новых блоков.

Таким образом, после выполнения сбора мусора мы избавимся от 
\begin{equation}
    \gamma - \vartheta = \frac{D_{\gamma}}{\tau}
\end{equation}
блоков для единого признака. Определим вектор $\vec{G}$ как единичный вектор
размерности $\frac{D_{\gamma}}{\tau}$. Тогда общее число удаленных в индексе блоков равно
\begin{equation}
    \vec{G} \cdot \vec{F} = \omega,
\end{equation}
где $\vec{F}$ — вектор размерности $\frac{D_{\gamma}}{\tau}$, на $i$-й позиции которого
стоит число признаков для документа $\vec{G}_i$.

Общий размер освобожденной памяти
\begin{equation}
    \omega + \gamma \cdot \left(\tau + \beta\right) = \chi,
\end{equation}
где второй член получается после очистки \textit{danglingBmap}.

Количество \textit{мусорных} блоков зависит от \textit{dangling} порога $d$ для
блока, очередности удаления документов в индексе и плотности признаков в
документах.

\paragraph{Вид контейнеров и размер их кодировки}

Согласно \cite{Features:2020}, в среднем в 1Gb
данных из $4\cdot 10^5$ документов, находится около $18 \cdot 10^7$ различных
признаков. Обозначим $C = \frac{18 \cdot 10^7}{4\cdot 10^5}$ как среднее количество
уникальных токенов в одном документе. Таким образом, $\alpha$ также равно $C\cdot D$.

Рассмотрим три случая заполненности битмап: разреженный, средний и плотный
при $4 \cdot 10^5$ добавленных документов из \cite{Features:2020}.

Для различного числа элементов применяется различная кодировка в
\textit{roaring bitmaps} (см. с.~\pageref{bitmap}). В нашем случае из-за большого
числа документов будут использованы битовый или бегущий контейнеры. Решение будет
принято, исходя из минимизации кодированной формы. Таким образом, мы приходим к
сравнению длин закодированных форм битмап $2\cdot c + 2$ \textit{VS} $2 + 4r$,
где $c$ — мощность битмапы, а $r$ — количество <<пробегов>>.

Предположим, что мы добавили $N$ документов.
\begin{enumerate}
    \item Плотные битмапы. Будет считать, что в битмапах $\geq \frac{3}{4}$
    ненулевых элементов. В случае битового контейнера размер после удаления
    $\frac{2}{3}$ документов будет равен
    \begin{equation}
        \frac{2}{3} \cdot \frac{3}{4} \cdot \left(2\cdot N + 2\right) = N + 1
    \end{equation}
    
    В случае бегущего контейнера все зависит от порядка удаления. В реальности
    мы чаще удаляем более старые блоки, следовательно, удаление будет не очень
    равномерным. Поделим мысленно битмапу на 3 равных по числу единиц блока.
    Из первого блока удалим все элементы, из второго — $\frac{2}{3}$, из
    третьего, самого <<нового>> — $\frac{1}{3}$. Таким образом будет удалено
    $\frac{2}{3}$ от общего числа документов.

    В этом случае размер контейнера будет равен
    \begin{multline}
        \frac{3}{4} \cdot \left(0 +
            \frac{1}{3} \cdot \left(4 \cdot \frac{1}{3} \cdot N + 2\right) +
            \frac{1}{3} \cdot \left(4 \cdot \frac{2}{3} \cdot \frac{N}{2} + 2\right)
            \right) =\\
            = \frac{3}{4} \cdot 2 \cdot \left(\frac{4 \cdot N}{9} + 2\right)
            = \frac{3}{2} \cdot \left(\frac{4 \cdot N}{9} + 2\right)
            = \left(\frac{2 \cdot N}{3} + 3\right)
    \end{multline}
    В первом блоке мы удалили все элементы — кодировать нечего, во втором блоке
    осталась $\frac{1}{3}$ элементов для кодировки, и они, вероятно, будут
    разбросаны равномерно по всему блоку, поэтому длина <<пробега>> будет около 1.
    В третьем блоке остается $\frac{2}{3}$ элементов, что дает возможность
    предположить, что средняя длина <<пробега>> около 2.

    Получается, что при данных условиях будет использован механизм бегущего контейнера.

    \item Битмапы средней плотности. Будет считать, что в битмапах $~ \frac{1}{2}$
    ненулевых элементов. В случае битового контейнера размер после удаления
    $\frac{2}{3}$ документов будет равен
    \begin{equation}
        \frac{2}{3} \cdot \frac{1}{2} \cdot \left(2\cdot N + 2\right) = \frac{2\cdot N}{3} + \frac{2}{3}
    \end{equation}

    В случае бегущего контейнера будем использовать алгоритм для плотных битмап.
    В этом случае размер контейнера будет равен
    \begin{multline}
        \frac{1}{2} \cdot \left(0 +
            \frac{1}{3} \cdot \left(4 \cdot \frac{1}{3} \cdot N + 2\right) +
            \frac{1}{3} \cdot \left(4 \cdot \frac{2}{3} \cdot N + 2\right)
            \right) =\\
            = \frac{1}{6} \cdot \left(\frac{4 \cdot N}{3} + 4\right)
            = \left(\frac{2 \cdot N}{9} + \frac{2}{3}\right)
    \end{multline}
    В первом блоке мы удалили все элементы — кодировать нечего, во втором блоке
    осталась $\frac{1}{3}$ элементов для кодировки, и они, вероятно, будут
    разбросаны равномерно по всему блоку, следовательно, длина <<пробега>> будет около 1.
    В третьем блоке блоке длина <<пробега>> также будет 1 из-за разреженности битмап.

    Получается, что при данных условиях будет использован механизм бегущего контейнера.

    \item Разреженные плотности. Будет считать, что в битмапах $~ \frac{1}{4}$
    ненулевых элементов. В случае битового контейнера размер после удаления
    $\frac{2}{3}$ документов будет равен
    \begin{equation}
        \frac{2}{3} \cdot \frac{1}{4} \cdot \left(2\cdot N + 2\right) = \frac{N}{3} + \frac{1}{3}
    \end{equation}

    В случае бегущего контейнера будем использовать принцип удаления как и для
    плотных битмап. В этом случае размер контейнера будет равен
    \begin{multline}
        \frac{1}{4} \cdot \left(0 +
            \frac{1}{3} \cdot \left(4 \cdot \frac{1}{3} \cdot N + 2\right) +
            \frac{1}{3} \cdot \left(4 \cdot \frac{2}{3} \cdot N + 2\right)
            \right) =\\
            = \frac{1}{12} \cdot \left(\frac{4 \cdot N}{3} + 4\right)
            = \left(\frac{N}{9} + \frac{1}{3}\right)
    \end{multline}
    В первом блоке мы удалили все элементы — кодировать нечего, в остальных блоках
    длина <<пробега>> будет равна 1 из-за разреженности битмап.

    Получается, что при данных условиях будет использован механизм бегущего контейнера.
\end{enumerate}

Таким образом, при работе нашего прототипа с большим числом документов всегда
будет выбран бегущий контейнер.

\paragraph{Количество <<мусорных>> блоков}

Рассчитаем число <<мусорных блоков>>. Общий размер индекса
\begin{equation}
    \left\lceil\frac{N}{\tau}\right\rceil \cdot F = \psi
\end{equation}
блоков.

Таким образом, в случае плотных битмап, последовательного удаления и достаточного
количества удаленных элементов $D \gg d$ ожидается, что в индексе образуется
\begin{equation}
    \left\lfloor\frac{D}{\tau}\right\rfloor \cdot F = \zeta
\end{equation}
мусорных блоков. Последние $F$ блоков учитываем, если 
\begin{equation}
    D \% \tau \geq \kappa,
\end{equation}
где
\begin{equation}
    \kappa = \frac{d}{\tau}
\end{equation}

Таким образом, при сборе мусора будет выявлено
\begin{equation}
    b \in \left[0;\zeta + F\right]
\end{equation}
<<мусорных>> блоков.

Логично предположить, что после удаления <<мусорных>> блоков и завершения операций
записи и слияния на заднем фоне ожидается ускорение операции поиска признаков в 
\begin{equation}
    \frac{\psi - b}{\psi}
\end{equation}
раз.

Таким образом, для случая плотных битмап мы ожидаем, что операция поиска потребует
в 3 раза меньше времени, чем поиск в <<мусорном>> индексе.

В случае битмап средней плотности с <<заселенностью>> ~$\frac{1}{2}$ ожидается
уменьшение числа <<переполненных мусорных>> блоков в 2 раза, и мы
ожидаем, что операция поиска потребует в $\frac{3}{2}$ раза меньше времени, чем поиск в
<<мусорном>> индексе.

В случае удаления поочередно по одному документу с каждого блока в индексе, при
\begin{equation}
    \frac{D}{N} \leq \kappa
\end{equation}
удаления блоков при сборе мусора не произойдет вовсе, ведь во всех блоках будет
недостаточно удаленных документов для очистки. Такой случай нам неинтересен из
практических соображений.

Аналогично неинтересен случай, когда признаки слишком уникальны для каждого документа,
так что мощности битмап минимальны. Тогда тоже не произойдет удаления при чистке
мусора вообще. Это выполнится при плотности распределения признаков в документах
$\mu \leq \kappa$. Данный случай не предоставляет практического интереса в нашей работе.

\subsubsection{Алгоритм <<мгновенного удаления>>}

Допустим, мы добавили $N$ документов в индекс и удалили $D$ документов. Мы
проставим $\alpha$ ~(\ref{alpha}) дополнительных бит в битмапах удаленных элементов для нужных блоков.
Эти биты заполнятся в $b$ блоках, что добавит $b$ битмап в \textit{первичный}
индекс. Итого получится
\begin{equation}
    \alpha + b \cdot C \cdot (\tau + \beta) = \eta
\end{equation}
аналогично ~(\ref{eta}).

Также учитываем размер \textit{doc2FieldFeature}: 
\begin{equation}
    \vec{N} \cdot \vec{F} = C \cdot N= \pi,
\end{equation}
— количество всех признаков для документов. Таким образом, в данном алгоритме будет выделено 
\begin{equation}
    \eta + \pi
\end{equation}
дополнительной памяти.

Самое важное, что данная структура не уничтожается и переносится на диск для
удаления элементов из более взрослых уровней дерева, что делает модель менее эффективной по
использованию памяти, чем алгоритм сбора мусора. Логично предположить, что из-за
операций с дополнительной памятью при поиске, чтении и удалении время работы и
поиска в алгоритме <<мгновенного>> удаления будут хуже, что мы и проверим на эксперименте.

Сравним память, используемую в алгоритме сбора мусора $\chi$ против $\eta + \pi$,
используемой во втором подходе.

\begin{multline}
    \eta + \pi - \left(\omega + \gamma \cdot \left(\tau + \beta\right)\right) =
    \alpha + \left(b \cdot C - \gamma\right) \cdot (\tau + \beta) + C \cdot N - \frac{D_{\gamma}}{\tau} \cdot C \geq \\
    \geq C \cdot \left(D + b \cdot (\tau + \beta) + N - \frac{D_{\gamma}}{\tau}\right) - b \cdot \left(\tau + \beta\right) \geq
    C \cdot N + b \cdot \left(\tau + \beta\right) \cdot (C - 1) \geq C \cdot N
\end{multline}

Таким образом, получается, что алгоритм сбора мусора должен экспоненциально
выигрывать по времени исполнения по сравнению с алгоритмом <<мгновенного>> удаления.