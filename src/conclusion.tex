\newpage
\section{Заключение}

В работе проанализированы существующие подходы к сбору данных в базах данных
и поисковых системах, т.~е. эффективному и своевременному удалению объектов,
потерявших актуальность и/или указывающих на несуществующие документы.
Предложен подход к решению этой задачи --- периодический сбор мусора в блоках
данных при превышении числа удаленных документов порогового значения,
позволяющий добиться хорошей производительности запросов по вхождениям
ключа при фиксированном количестве добавленных и удаленных документов. Рассмотрено поведение
предлагаемого алгоритма в сравнении с известными подходами для некоторых
сценариев использования, и показано экспериментально, что
даже при большом количестве добавленных документов ($\ge 10^{4}$)
предложенный алгоритм дает выигрыш во времени поиска. Также
простой подход дает экспоненциальный рост времени выполнения от количества
документов, а в случае разработанного алгоритма это время практически
не растёт.

Получена теоретическая оценка размеров дополнительной памяти для реализации
обоих подходов в зависимости от количества добавленных и удаленных документов,
разреженности битовых карт и порядка удаления, подтверждённая экспериментально.

Возможными направлениями дальнейшего развития данной темы могли бы
стать разработка оценки приоритетности очистки блоков, в том числе с учётом
общего числа удаленных документов, сравнительный анализ поведения для других
видов LSM-деревьев, получение теоретической оценки размера метаданных при более общих
исходных предположениях (например, при динамическом определении порогового значения
и времени старта алгоритма), а также детальное построение эффективного
параллелизуемого алгоритма.