\newpage
\section{Обзор известных способов сбора мусора при работе с данными}

\subsection{Поисковые структуры данных}

\subsubsection{Общие замечания}

Основная идея удаления при работе с большим количеством даных заключается в задержке
операции фактического удаления на определенное время и замену на логическое удаление:
поисковая структура во время поиска данных игнорирует указанные записи. 

При необходимости удалить ключ и соответствующее ему значение в файл данных добавляется
специальная запись об удалении, иногда называемую отметкой об удалении,
\textit{tombstone}. При слиянии сегментов структуры данных эта отметка
указывает процессу слияния игнорировать все предыдущие значения для удаленного ключа.
Время от времени запускается в фоне процесс слияния и уплотнения, чтобы объединить файлы
сегментов и отбросить перезаписанные или удаленные значения.

Заметим, что периодически бывает недостаточно просто дописать в журнал новое событие,
указывающее на то, что предыдущие данные считаются удаленными, — надо действительно
переписать историю и притвориться, будто эти данные никогда не существовали. 
База данных Datomic \cite{Datomic:2021} называет такую функцию вырезанием,
а в системе контроля версий Fossil \cite{Fossil:2017} аналогичная концепция
именуется отторжением. В обоих случаях используется глобальные прерывание
и необратимая чистка всей истории \cite{Kleppman:2017}, что является главным недостатком
обоих подходов, так как глобальное прерывание поисковой системы, которой пользуются миллионы
пользователей повлечет за собой убытки, а чистка всех уровней структуры — процедура
дорогостоящая в терминах затрат по времени из-за обращений в память.  

\subsubsection{FAst DEletes + Key Weaving Storage Layout}

При работе с LSM-деревьям, которые являются универсальными компонентами масштабных
поисковых систем, удаление элементов — очень дорогостоящая и ресурсозатратная операция.
Требуется удалить элемент из всех уровней, что требует частой записи и чтения на диск.
Поэтому в современных механизмах, использующих LSM механизмы, операция удаления
рассматривается как "второсортная" операция в плане последовательности выполнения.
Ранее (cм. с.~\pageref{amplification}) было описано, что данный подход приводит к
усилению пространства и записи, увеличивает вероятность поиска несуществующих
элементов и проблем с безопасностью.

Алгоритм Lethe \cite{Lethe:2020} решает проблему отложенности операции удаления и
эффективного последовательности удалений в LSM-деревьях. 

Главный принцип первой части алгоритма, FADE, FAst DEletes, заключается в 
версионировании маркеров удаления для гарантии, что все присутствующие отметки об
удалении в дереве имеют версию не превышающую пороговую. Таким образом, при присвоении
маркеру версии выше пороговой, запускается механизм слияния и сжатия.

Вторая часть алгоритма, KiWi, Key Weaving Storage Layout, добавляет
дополнительный слой к уровням хранилища LSM-деревьев. К дополнение к уровням деревьев,
файлам уровня и страницам файла добавляются "плитки" удаления. Плитка принадлежит 
файлу и состоит из страниц. Она представляет собой логическую коллекцию последовательных
страниц в файле, разделенных по версии маркера удаления и поделенных на страницы.
Таким образом, алгоритм позволяет группировать записи по времени логического удаления,
тем самым уменьшая количества обращений к диску. Для качественного бинарного поиска KiWi
сортирует элементы внутри внутри страницы по ключу.

Особое достоинство, имеющееся у Lethe, — выигрыш в усилении памяти, производительности
чтения и  количестве обращения чтений/записи на диск по сравнению в RocksDB,
а потому рассмотрение данного подхода к версионировании данных представляет практический интерес.

\subsection{Сборщики мусора в поисковых системах и базах данных}

\subsubsection{Библиотека Lucene}

Lucene\cite{Lucene:2008} — свободная библиотека для высокопроизводительного
полнотекстового поиска фонда Apache и построенный на нем Elasticsearch\cite{Elasticsearch:2020},
популярная поисковая система, также пользуются маркером удаления, откладывая
момент фактического удаления до слияния поискового дерева с SS-таблицами на
диске \cite{Elasticsearch1:2021}\cite{Elasticsearch2:2021}.

\subsubsection{Поисковая система Elasticsearch}

\paragraph{Garbage First Garbage Collector}

В алгоритме G1 память разбивается на множество регионов одинакового размера.
Размер этих регионов зависит от общего размера кучи и по умолчанию выбирается
так, чтобы их было не больше 2048, обычно получается от 1 до 32 МБ.
Исключение составляют только так называемые громадные (humongous)
регионы, которые создаются объединением обычных регионов для размещения очень
больших объектов. Малые сборки выполняются периодически для очистки младшего
поколения и переноса объектов в регионы Survivor, либо их повышения до
старшего поколения с переносом в Tenured. Над переносом объектов трудятся несколько
потоков, и на время этого процесса работа основного приложения останавливается.
Это уже знакомый нам подход из рассмотренных ранее сборщиков, но отличие состоит
в том, что очистка выполняется не на всем поколении, а только на части регионов,
которые сборщик сможет очистить не превышая желаемого времени. При этом он выбирает
для очистки те регионы, в которых, по его мнению, скопилось наибольшее количество
мусора и очистка которых принесет наибольший результат. Отсюда как раз название
Garbage First — мусор в первую очередь \cite{G1GC:2018}.

Таким образом, плюсами данного подхода являются зависимость выбора региона для "уборки" 
от загрузки, ограниченное время исполнения и приоритизация регионов с наибольшим
количеством мусора.

\subsubsection{RediSearch}

Подход RediSearch к сборке мусора\cite{RediSearch:2021} предполагает фоновую работу,
во время которой каждый блок параллельно сканируется на наличие битых ссылок. Далее,
группируясь, параллельные процессы оповещают главный процесс, какие элементы
требуются для удаления и тогда он блокирует блок на короткое время, так как данные,
которые требуются удалить, ему уже известны. Основное преимущество этого подхода
заключается в возможности фонового прохода и определения \textit{повисших документов}
без глобальных прерываний.

\subsubsection{Инвертированные индексы GIN в PostgreSQL}

Идея GIN\cite{GIN:2020} в PostgreSQL — перестройка всего индекса (дерева) при достижении счетчика 
\textit{повисших ссылок} высокого порогового значения. На практике GIN индексы
показывают хороший результат по сравнению с GiST индексами. В каждой строке таблицы
существует поле $created\_by$, содержащее идентификатор транзакции, вставившей эту
строку в таблицу. Также в каждой строке таблицы есть поле $deleted\_by$, изначально
пустое. Если транзакция удаляет строку, то строка на самом деле не удаляется из базы
данных, а помечается для удаления путем установки значения этого поля в соответствии
с идентификатором запросившей удаление транзакции. В дальнейшем, когда уже никакая
транзакция точно не обратится к удаленным данным, процесс сборки мусора БД удалит
все помеченные для удаления строки и освободит занимаемое ими место.

Пользователь, предполагая распределения количества операций добавления и удаления,
может выбрать оптимальное пороговое значение.

\subsubsection{Broom алгоритм для работы с большими данными}

Broom алгоритм для работы с большими данными в задачах анализа данных и машинного обучения
предлагает разделение данных на 3 категории:
\begin{itemize}
    \item переносимые (transferable) используются для объектов, которые сохраняются между
    задачами и могут быть использованы другими задачами в течение промежутка времени;
    \item task-scoped данные, созданные для конкретной задачи;
    \item временные (temporary) регионы используются для хранения временных объектов.
\end{itemize}

Для конкретной категории данных выставлялось свое пороговое значение позволенных
\textit{повисших документов}, тем самым регулируя частоту очистки каждого из секторов.
Оптимальная группировка элементов в программе вызвало снижения времени работы сборщика
мусора на 34\%, однако такие значимые результаты удалось показать не для любых данных
\cite{BigData:2018}.

\subsection{Алгоритмы работы с \textit{повисшими ссылками}}

\subsubsection{PageChaser}

PageChaser\cite{PageChaser:2009} же использует собственный набор эвристик, большинства
которых о поиске новых ссылок, валидных для документа. Например, PageChaser ищет все
ссылки, которые связанные с пропавшим документам, из рассчета, что в каком-то из них
удастся найти обновленную ссылку на документ.

\subsubsection{Self-Evolving Database}

Алгоритм SEDB\cite{SEDB:1998} в случае удаления элемента объявляет все ссылки в других
документах указывающие на него \textit{повисшими}. Для сохранения топологии сети
создается дополнительный элемент, не несущий никакого информации кроме всех исходящих
ссылок из пропавшего документа, а сами ссылки удаляются. Данный подход
будет сложно использовать при работе с битмапами.

К относительным преимуществам этих методов можно отнести возможность запуска в фоновом
режиме и передачи управления процессу только в случае получения положительного ответа 
после завершения операций.
