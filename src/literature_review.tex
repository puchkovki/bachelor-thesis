\newpage
\section{Обзор известных способов сбора мусора при работе с данными}

\subsection{Поисковые структуры данных}

\subsubsection{Общие замечания}

Основная идея удаления при работе с большим количеством данных заключается в задержке
операции фактического удаления на определенное время и замену на логическое удаление:
поисковая структура во время поиска данных игнорирует указанные записи. 

При необходимости удалить ключ и соответствующее ему значение в файл данных добавляется
специальная запись об удалении, иногда называемую отметкой об удалении,
\textit{tombstone}. При слиянии сегментов структуры данных эта отметка
указывает процессу слияния игнорировать все предыдущие значения для удаленного ключа.
Время от времени запускается в фоне процесс слияния и уплотнения, чтобы объединить файлы
сегментов и отбросить перезаписанные или удаленные значения.

Заметим, что периодически бывает недостаточно просто дописать в журнал новое событие,
указывающее на то, что предыдущие данные считаются удаленными, — надо действительно
переписать историю и притвориться, будто эти данные никогда не существовали. 
База данных \textit{Datomic} \cite{Datomic:2021} называет такую функцию вырезанием,
а в системе контроля версий \textit{Fossil} \cite{Fossil:2007} аналогичная концепция
именуется отторжением. В обоих случаях используется глобальные прерывание
и необратимая чистка всей истории \cite{Kleppman:2017}, что является главным недостатком
обоих подходов, так как глобальное прерывание поисковой системы, которой пользуются миллионы
пользователей повлечет за собой убытки, а чистка всех уровней структуры — процедура
дорогостоящая в терминах затрат по времени из-за обращений в память.  

\subsubsection{FAst DEletes + Key Weaving Storage Layout}

При работе с LSM-деревьям, которые являются универсальными компонентами масштабных
поисковых систем, удаление элементов — очень ресурсозатратная операция. Требуется
удалить элемент из всех уровней, что приводит к частой записи и чтению с диска.
Поэтому в современных механизмах, использующих LSM-деревья, операция удаления
рассматривается как <<второсортная>> операция в плане приоритетности выполнения.
Ранее (cм. с.~\pageref{amplification}) было описано, что данный подход приводит к
усилению пространства и записи, увеличивает вероятность долгого поиска
несуществующих элементов и создает проблемы с безопасностью.

Алгоритм \textit{Lethe} \cite{Lethe:2020} решает проблему отложенной операции удаления и
эффективной последовательности удалений в LSM-деревьях. 

Главный принцип первой части алгоритма, \textit{FAst DEletes}, заключается в версионировании
маркеров удаления для гарантии, что все присутствующие отметки об удалении в
дереве имеют версию, не превышающую пороговую. Таким образом, при присвоении
маркеру версии выше пороговой, запускается механизм слияния и сжатия.

Вторая часть алгоритма, \textit{Key Weaving Storage Layout}, добавляет дополнительный
слой к уровням хранилища LSM-деревьев. К дополнение к уровням деревьев, файлам
уровня и страницам файла добавляются <<плитки>> удаления. Плитка принадлежит
файлу и представляет собой логическую коллекцию последовательных страниц в нем,
разделенных по версии маркера удаления. Таким образом, алгоритм позволяет
группировать записи по времени логического удаления, тем самым уменьшая количества
обращений к диску. Для качественного бинарного поиска \textit{KiWi} сортирует элементы
внутри страницы по ключу.

Алгоритм \textit{Lethe} выигрывает по сравнению с \textit{RocksDB} и получает преимущества в:
\begin{itemize}
    \item усилении памяти;
    \item производительности чтения;
    \item количествах обращений чтения/записи на диск.
\end{itemize}

Поэтому рассмотрение данного подхода к версионировании данных представляет
практический интерес.

\subsection{Сборщики мусора в поисковых системах и базах данных}

\subsubsection{\textit{Fast and endurant garbage collection}}

Алгоритм \textit{FeGC} описывает эффективную схему сбора мусора для флеш-памяти
в хранилищах данных. Для механизмов работы с флеш-памятью характерна преднамеренная
осторожность к обновлению/удалению информации, ведь обновление всего 1 байте требует
медленной операции очистки блока и несколько операций чтения/записи. Также требуется
учесть, что количество операций очистки для каждого блока ограничено, что выдвигает
проблему эффективности сбора мусора на передний план.

Данный алгоритм предлагает схему, минимизирующую издержки сбора мусора в затратах
по времени и энергии, а также балансирующую число операций очистки для флеш-памяти
в целом.

Решение предлагает определить новую оценку блоков памяти, <<вес>> блока в зависимости
от возраста:

\begin{equation}
    \text{CwA} = \sum_{i=1}^n \text{age}_i,\\
    \text{age}_i = \text{time}_c - \text{time}_i,
\end{equation}
где $\text{time}_c$ — время в момент расчета оценки, а $\text{time}_i$ — момент
времени, когда блок стал недействительным. Блок с наибольшим \textit{CwA}
выбирается приоритетным для удаления.

Также алгоритм делит блоки на холодные и горячие для последующего выделения их
молодым и старым блокам соответственно. Последняя классификация происходит по
количеству операций очистки блоков \cite{FeGC:2011}\cite{FeGC:2014}.

Решение представляет практический интерес, так как меньшие компоненты LSM-дерева
часто хранятся в энергозависимой памяти, для которой характерны проблемы, с
которыми столкнулись авторы статьи.