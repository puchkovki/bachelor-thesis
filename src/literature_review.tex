\newpage
\section{Обзор известных способов сбора мусора в работе с данными}

\subsection{Библиотека для высокопроизводительного полнотекстового поиска Lucene}
\label{subsection:b_tree_indexes}

\subsubsection{Поисковая система Elasticsearch}

Lucene — известный поисковый движок, и, построенный на нем Elasticsearch —
популярная поисковая система отсрочивает удаления до слияния с более большими индексами. 

Большинство поисковых систем, даже такие повсеместно используемые, как Lucene (Elasticsearch)
и PostgreSQL, даже обходятся этим случаем, лишь помечая элементы удаленными отдельным битом.
Фактическое удаление происходит лишь при слиянии поискового дерева с SS-таблицами на диске.

\subsubsection{Сборщик CMS (Concurrent Mark Sweep)}

В Elasticsearch по умолчанию за сбор мусора отвечает CMS. Сборщик CMS достаточно интеллектуальный. Например, он старается разносить во времени малые
и старшие сборки мусора, чтобы они совместно не создавали продолжительных пауз в работе приложения
(дополнительные подробности об этом разнесении в комментариях). Для этого он ведет статистику
по прошедшим сборкам и исходя из нее планирует последующие.

\subsubsection{Garbage First Garbage Collector}

Первое, что бросается в глаза при рассмотрении G1 — это изменение подхода к организации кучи.
Здесь память разбивается на множество регионов одинакового размера. Размер этих регионов зависит
от общего размера кучи и по умолчанию выбирается так, чтобы их было не больше 2048,
обычно получается от 1 до 32 МБ. Исключение составляют только так называемые громадные (humongous)
регионы, которые создаются объединением обычных регионов для размещения очень больших объектов.
Малые сборки выполняются периодически для очистки младшего поколения и переноса объектов
в регионы Survivor, либо их повышения до старшего поколения с переносом в Tenured.
Над переносом объектов трудятся несколько потоков, и на время этого процесса работа основного
приложения останавливается. Это уже знакомый нам подход из рассмотренных ранее сборщиков,
но отличие состоит в том, что очистка выполняется не на всем поколении, а только на части регионов,
которые сборщик сможет очистить не превышая желаемого времени. При этом он выбирает для очистки те регионы,
в которых, по его мнению, скопилось наибольшее количество мусора и очистка которых принесет наибольший результат.
Отсюда как раз название Garbage First — мусор в первую очередь.

\subsection{Инвертированные индексы GIN и PostgreSQL}

\subsubsection{Общие замечания}

Идея же GIN в PostgreSQL в предоставление пользователю решать, какой процент “повисших” ссылок
от общего числа документов будет триггером к перестройке индекса. 

\subsubsection{Неперемещающий сборщик мусора}

Альтернативный способ — перестройка всего индекса (дерева) при достижении счетчика “повисших”
документа высокого порогового значения. Похожий способ используется в GIN индексах базы данных PostgreSQL.

Они показывают хороший результат, по сравнению с GiST индексами. В каждой строке таблицы есть поле
created-by, содержащее идентификатор транзакции, вставившей эту строку в таблицу. Более того, в каждой
строке таблицы есть поле deleted-by, изначально пустое. Если транзакция удаляет строку, то строка
на самом деле не удаляется из базы данных, а помечается для удаления путем установки значения этого поля
в соответствии с идентификатором запросившей удаление транзакции. В дальнейшем, когда уже никакая транзакция
точно не обратится к удаленным данным, процесс сборки мусора БД удалит все помеченные для удаления строки
и освободит занимаемое ими место.

\subsection{Хеш-таблицы и другие}

\subsubsection{Общие замечания}

(Kleppmann). Удаление записей. При необходимости удалить ключ и соответствующее ему значение
приходится добавлять в файл данных специальную запись об удалении
(иногда называемую отметкой об удалении (tombstone)). При слиянии сегментов журнала эта отметка
указывает процессу слияния игнорировать все предыдущие значения для удаленного ключа.
Время от времени запускаем в фоне процесс слияния и уплотнения, чтобы объединить файлы сегментов
и отбросить перезаписанные или удаленные значения.

Периодически бывает недостаточно просто дописать в журнал новое событие, указывающее на то,
что предыдущие данные считаются удаленными, — надо действительно переписать историю и притвориться,
будто эти данные никогда не существовали. БД Datomic называет такую функцию вырезанием,
а в системе контроля версий Fossil аналогичная концепция именуется отторжением.
В обоих случаях используется глобальные прерывание и необратимая чистка всей истории.

\subsection{Алгоритм Broom для работы с большими данными}

\subsubsection{Общие замечания}

Broom алгоритм для работы с большими данными в задачах анализа данных и машинного обучения
предлагает разделение данных на 3 категории: 
    • (transferable) переносимые используются для сохранения объектов, что сохраняются
    между задачами и могут быть использованы разными задачами в течение времени
    • (task-scoped) созданные для конкретной задачи
    • (temporary) временные регионы используются для хранения временных объектов
Правильно группируя элементы у них вышло добиться снижения времени работы программы на 34\%.
Правда так значительно это сработало только для их данных.

\subsection{Self-Evolving Database (SEDB)}

\subsubsection{Общие замечания}

В SEDB для автоматического починки висячих ссылок. В случае удаления элемента все ссылки
в других документах, указывающие на него объявляются висячими. Для сохранения топологии
сети создается дополнительный элемент, не несущий никакого информации кроме всех исходящих
ссылок из пропавшего документа.

\subsection{PageChaser}

\subsubsection{Общие замечания}

PageChaser же использует собственный набор эвристик, большинства которых о поиске новых
ссылок, валидных для документа. Например, PageChaser ищет все ссылки, которые
связанные с пропавшим документам, из рассчета, что в каком-то из них удастся найти обновленную ссылку на документ.

\subsection{RediSearch}

\subsubsection{Общие замечания}

GC в RediSearch предлагает фоновую работу GC, во время которой каждый блок параллельно
сканируется на наличие битых ссылок. Далее, группируясь параллеьные процессы оповещают
главный процесс, что требуется для удаления и тогдда он блокирует lock на короткое время,
так как данные, что удалить ему уже известны.